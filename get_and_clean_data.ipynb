{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b656f9",
   "metadata": {},
   "source": [
    "# Importing Data from Fitbit \n",
    "Fitbit offers an export option for all of a user's data. \n",
    "This data is exported in multiple folders, each containing multiple JSON and .csv files. \n",
    "For this project, I am interested in the following data: \n",
    "- bpm \n",
    "- sleep type (heavy, light, REM) and length of each sleep type\n",
    "- sleep score \n",
    "- step data\n",
    "- active minutes (light, moderate, and very active minutes) \n",
    "- resting heartrate\n",
    "- outside temperature at bedtime (10pm local) \n",
    "\n",
    "Each section has a 2 row sample of the dataframe at the end. \n",
    "\n",
    "The data is all time based. The goal is to reduce all of the data to get a summary for each day. \n",
    "For example, the bpm data is recorded every 5 seconds, and I will reduce it to a daily summary.  \n",
    "\n",
    "**All resulting dataframes will have one datapoint per day, and will be indexed by date (US/Pacific).**\n",
    "\n",
    "All of the data is then pickled (as loading from the pickle will be much faster than re-reading the JSON). \n",
    "Resulting files used in the analysis will be: \n",
    "- bpm.pkl \n",
    "- sleep_score.pkl\n",
    "- sedentary_minutes.pkl\n",
    "- lightly_active.pkl\n",
    "- moderately_active.pkl\n",
    "- very_active.pkl\n",
    "- step_daily.pkl\n",
    "- resting_heartrate.pkl\n",
    "\n",
    "** When you're all done, make sure each data frame has the expect # rows and the expected datatype\n",
    "Make sure each pickled file exists, and also that its being sourced NOT from the test dir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdf781",
   "metadata": {},
   "source": [
    "Tables:\n",
    "- bpm (done)\n",
    "- sleep levels (done)\n",
    "- sleep score (done)\n",
    "- steps (done)\n",
    "- sedentary minutes (done)\n",
    "- lightly active minutes (done)\n",
    "- moderately active minutes (done)\n",
    "- very active minutes (done)\n",
    "- resting heartrate (done)\n",
    "- temperature \n",
    "- etc.?\n",
    "merge all the tables together using date as the primary key \n",
    "daily sleep will be the response variable \n",
    "everything else will be explanatory variables \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "93539940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "f6fbd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where most of this data lives \n",
    "phys_dir = '/Users/jackiekinsler/projects/sleep_analysis_py/physical_data/Physical_Activity'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cae475",
   "metadata": {},
   "source": [
    "### IMPORT FROM JSON FUNCTION\n",
    "This function will help import and concatenate the many JSON files that compromise each data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bb97544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_from_dir(file_prefix, directory):\n",
    "    \"\"\"Reads JSON file(s) in a folder and returns a single dataframe. \n",
    "    Takes strings of file_prefix and directory as input. \n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file_prefix in file: \n",
    "            dfs.append(pd.read_json(f\"{directory}/{file}\"))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276907e",
   "metadata": {},
   "source": [
    "### BPM\n",
    "Import the bpm data from JSON. \n",
    "The JSON data contains a date field and a'value' field. \n",
    "The 'value' field contains a dictionary with 'bpm' and 'confidence'. \n",
    "The data is imported, the nested 'value' column is unnested. \n",
    "The index is also reset, as the index values are not unique.\n",
    "\n",
    "The data is taken every 5 seconds. The data will be reduced to get daily values for max_bpm and average_bpm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9409e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bpm_nested = import_data_from_dir('heart_rate-', '/Users/jackiekinsler/projects/sleep_analysis_py/physical_data/heart_rate')\n",
    "bpm_nested.to_pickle('data/bpm_nested.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "62cbeeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_nested = pd.read_pickle('data/bpm_nested.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "a4d334b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index needs to be reset as there are repeated values (will come into play in the concat function later!)\n",
    "bpm_nested.reset_index(inplace = True)\n",
    "# Explode the dictionary in the values column to get 'bpm' and 'confidence'\n",
    "bpm_explode = pd.json_normalize(bpm_nested['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "c9a84981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, two columns are brought together: the dateTime column from bpm_nested, \n",
    "# and the two exploded columns (bpm, confidence) that makeup bpm_explode \n",
    "bpm_detail = pd.concat([bpm_nested['dateTime'], bpm_explode], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "dc8893be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dateTime as a DatetimeIndex. Normalize will drop the time information from the datetime \n",
    "bpm_detail.set_index(pd.DatetimeIndex(bpm_detail['dateTime']).normalize(), inplace=True)\n",
    "# Drop the old dateTime column\n",
    "bpm_detail.drop(['dateTime','confidence'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "b8f5e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_detail.to_pickle(\"data/bpm_detail.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "cf7c2f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bpm</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bpm  confidence\n",
       "dateTime                   \n",
       "2022-03-10   54           3\n",
       "2022-03-10   53           2"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpm_detail.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881bd25c",
   "metadata": {},
   "source": [
    "Now we will aggregate the data and get some daily stats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "029dc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_grouped = bpm_detail.groupby(by='dateTime')\n",
    "bpm = bpm_grouped.agg(['max', 'mean'], axis=1)\n",
    "# Doing the aggregate function creates a multiindexed object (which is annoying for plotting). \n",
    "# Drop this added level. \n",
    "bpm.columns = bpm.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "987f9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm.to_pickle('data/bpm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "894287fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>108</td>\n",
       "      <td>77.523560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20</th>\n",
       "      <td>124</td>\n",
       "      <td>69.342717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bpm           \n",
       "            max       mean\n",
       "dateTime                  \n",
       "2017-07-19  108  77.523560\n",
       "2017-07-20  124  69.342717"
      ]
     },
     "execution_count": 1274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e38151",
   "metadata": {},
   "source": [
    "### SLEEP DETAIL\n",
    "Import the detailed sleep data from JSON.  \n",
    "The raw JSON has many columns, but the 'levels' columnn is perhaps the most interesting.  \n",
    "The 'levels' column contains a dictionary of data about the amount of time spent in each sleep type.  \n",
    "Sleep types include:\n",
    "- deep\n",
    "- wake\n",
    "- light\n",
    "- REM \n",
    "\n",
    "The 'levels' column will be unnested and added back to the dataframe.  \n",
    "It is important to note that there may be multiple sleep entries for a given day (for example: if there was a long waking period in the middle of sleeping). \n",
    "\n",
    "The sleep details for these days will be aggregated into one day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "e3939d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import from the sleep directory \n",
    "sleep_nested = import_data_from_dir('sleep-', '/Users/jackiekinsler/projects/sleep_analysis_py/physical_data/Sleep')\n",
    "# There are some entries that are recorded twice... this is because they are in two of the JSON datasets \n",
    "# Remove duplicate logId entries \n",
    "sleep_nested.drop_duplicates(subset=['logId'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521d9b0",
   "metadata": {},
   "source": [
    "Originally, I tried using the `json_normalize` function to get these vaules, but it was dropping a lot of rows for an unknown reason. I think it had to do with unexpected handing of \"None\" values. \n",
    "Instead, the below function is used from https://medium.com/analytics-vidhya/exploring-your-fitbit-sleep-data-with-python-pandas-and-seaborn-in-jupyter-notebook-a997f17c3a42\n",
    "I'd love to use the faster `json_normalize` instead of `apply`, but `apply` is quick enough on this small dataset. \n",
    "NOTE: In other instances where I use `json_normalize` I checked that it did not drop rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "id": "43828e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if data exists before trying to extract it \n",
    "def get_minutes(levels, sleep_phase):\n",
    "    if not levels.get('summary'):\n",
    "        return None\n",
    "    if not levels.get('summary').get(sleep_phase):\n",
    "        return None\n",
    "    if not levels.get('summary').get(sleep_phase).get('minutes'):\n",
    "        return None\n",
    "    return levels['summary'][sleep_phase]['minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "id": "7c696e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_nested['deep_mins'] = sleep_nested.levels.apply(get_minutes, args=('deep',))\n",
    "sleep_nested['wake_mins'] = sleep_nested.levels.apply(get_minutes, args=('wake',))\n",
    "sleep_nested['light_mins'] = sleep_nested.levels.apply(get_minutes, args=('light',))\n",
    "sleep_nested['rem_mins'] = sleep_nested.levels.apply(get_minutes, args=('rem',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "id": "95b32052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns of interest\n",
    "sleep_minutes = sleep_nested.loc[:,[\n",
    "    'dateOfSleep', \n",
    "    'minutesAsleep', \n",
    "    'mainSleep', \n",
    "    'deep_mins', \n",
    "    'wake_mins', \n",
    "    'light_mins', \n",
    "    'rem_mins'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "4fd74965",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_detail = sleep_minutes.groupby(by='dateOfSleep').sum()\n",
    "sleep_detail.index = pd.to_datetime(sleep_detail.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "id": "dfddac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_detail.to_pickle(\"data/sleep_detail.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "id": "c9fd6afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutesAsleep</th>\n",
       "      <th>mainSleep</th>\n",
       "      <th>deep_mins</th>\n",
       "      <th>wake_mins</th>\n",
       "      <th>light_mins</th>\n",
       "      <th>rem_mins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateOfSleep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-25</th>\n",
       "      <td>471</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             minutesAsleep  mainSleep  deep_mins  wake_mins  light_mins  \\\n",
       "dateOfSleep                                                               \n",
       "2017-07-25             471          1      101.0       80.0       260.0   \n",
       "2017-07-30             237          1        0.0        0.0         0.0   \n",
       "\n",
       "             rem_mins  \n",
       "dateOfSleep            \n",
       "2017-07-25      110.0  \n",
       "2017-07-30        0.0  "
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_detail.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c69863",
   "metadata": {},
   "source": [
    "### SLEEP SCORE\n",
    "Sleep score is in a .csv with 1 row per sleep (there may be multiple sleeps per night). \n",
    "\n",
    "`overall_sleep` score is a sum of individual scores in sleep duration, sleep quality, and restoration\n",
    "- Excellent: 90-100\n",
    "- Good: 80-89\n",
    "- Fair: 60-79\n",
    "- Poor: Less than 60\n",
    "To understand more about the sleep score: https://help.fitbit.com/articles/en_US/Help_article/2439.htm\n",
    "\n",
    "The resulting dataframe is indexed by date, with `overall_score`, `sleep_resting_heartrate`, and `deep_sleep_in_min` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "id": "fac86fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sleep_score_full = pd.read_csv('/Users/jackiekinsler/projects/sleep_analysis_py/physical_data/Sleep/sleep_score.csv')\n",
    "# Keep only the rows of interest\n",
    "sleep_score_reduced = sleep_score_full.loc[:,['timestamp', 'overall_score', 'deep_sleep_in_minutes', 'resting_heart_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "id": "79b90062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert timestamp to a date, and then remove the time portion of the timestamp\n",
    "sleep_score_reduced['timestamp'] = pd.to_datetime(sleep_score_reduced['timestamp']).dt.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa214531",
   "metadata": {},
   "source": [
    "It is possible to have more than one entry per date (there may be multiple sleeps per night).  \n",
    "\n",
    "Below, the data is grouped by date. Then, a weighted average of the `overall_score` and `resting_heart_rate` is taken using the `deep_sleep_in_minutes` column. \n",
    "\n",
    "The `deep_sleep_in_minutes` is simply summed.\n",
    "This results in a table with unique dates. \n",
    "The date is then used as the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "id": "49877017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group entries by date \n",
    "grouped_by_time = sleep_score_reduced.groupby(by='timestamp')\n",
    "\n",
    "# Here, we return a series to maintain the column name (would be lost otherwise)\n",
    "overall_score = grouped_by_time.apply(\n",
    "        lambda x: \n",
    "        pd.Series({\n",
    "            'overall_score' : np.average(x.overall_score, weights=x.deep_sleep_in_minutes)\n",
    "        })\n",
    "    )\n",
    "sleep_resting_heartrate = grouped_by_time.apply(\n",
    "        lambda x: \n",
    "        pd.Series({ \n",
    "            'sleep_resting_heartrate' : np.average(x.resting_heart_rate, weights=x.deep_sleep_in_minutes)\n",
    "        })\n",
    "    )\n",
    "deep_sleep_in_min = pd.DataFrame(grouped_by_time['deep_sleep_in_minutes'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "id": "70765b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three columns into a new dataframe \n",
    "sleep_score = pd.concat([overall_score, sleep_resting_heartrate, deep_sleep_in_min], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "id": "cb8df452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to date only, instead of date and a midnight time stamp z\n",
    "sleep_score.index = pd.to_datetime(sleep_score.index.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "id": "2a4d966b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "      <th>sleep_resting_heartrate</th>\n",
       "      <th>deep_sleep_in_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-22</th>\n",
       "      <td>83.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-29</th>\n",
       "      <td>73.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall_score  sleep_resting_heartrate  deep_sleep_in_minutes\n",
       "2019-08-22           83.0                     48.0                    102\n",
       "2019-08-29           73.0                     52.0                     93"
      ]
     },
     "execution_count": 1329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_score.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "id": "bee27991",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_score.to_pickle(\"data/sleep_score.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c34a41",
   "metadata": {},
   "source": [
    "### STEPS\n",
    "Import steps data from JSON.  \n",
    "Steps data is recorded every few minutes. The number of steps for that period of time is recorded.   \n",
    "The data will be reduced to the total number of steps for each day.   \n",
    "\n",
    "Resulting table `step_daily` is date (in US/Pacific), and the total number of steps on that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c286fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step_detail = import_data_from_dir('steps-', phys_dir)\n",
    "step_detail.to_pickle(\"data/step_detail.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "id": "01627058",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_detail = pd.read_pickle('data/step_detail.pkl')\n",
    "# Convert the dateTime column from UTC to Pacific \n",
    "step_detail['dateTime'] = step_detail['dateTime'].dt.tz_localize('UTC').dt.tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "id": "32844615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of steps for each day \n",
    "step_daily = step_detail.groupby([step_detail['dateTime'].dt.date]).sum()\n",
    "# .groupby turns the grouped column (dateTime) into the index.\n",
    "# Use .to_datetime() to make it a DatetimeIndex\n",
    "step_daily.index = pd.to_datetime(step_daily.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "id": "dc72d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_daily.to_pickle('data/step_daily.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "id": "400add15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20</th>\n",
       "      <td>9033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "dateTime         \n",
       "2017-07-19   4040\n",
       "2017-07-20   9033"
      ]
     },
     "execution_count": 1339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_daily.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "id": "ca0d0ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value    11571\n",
       "Name: 2022-12-09 00:00:00, dtype: int64"
      ]
     },
     "execution_count": 1340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of getting a step value for a specific date \n",
    "step_daily.loc['2022-12-9']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5438ad",
   "metadata": {},
   "source": [
    "### ACTIVITY MINUTES\n",
    "\n",
    "Activity minutes are imported from JSON. \n",
    "The documentation does not provide information about what time zone the dateTime stamp is from. \n",
    "By looking at the data and aligning it with known activity on different days, I am making the assumption that the data is recorded in local time. Although, if it was recorded in UTC, the data would be off by 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "id": "32bcd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_activity_min(file_prefix, directory):\n",
    "    \"\"\"\n",
    "    For activity minutes only! Takes a file_prefix and directory, and returns a data table \n",
    "    with a DatetimeIndex and a value for activity minutes for that day. \n",
    "    \"\"\"\n",
    "    df = import_data_from_dir(file_prefix, directory)\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    # Create a DatetimeIndex from the dateTime column, then drop the original dateTime column \n",
    "    df.set_index(pd.DatetimeIndex(df['dateTime']), inplace=True)\n",
    "    df.drop('dateTime', axis=1, inplace=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "id": "27bf9f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing activity minutes \n",
    "sedentary_minutes = import_activity_min('sedentary_minutes', phys_dir)\n",
    "lightly_active = import_activity_min('lightly_active', phys_dir)\n",
    "moderately_active = import_activity_min('moderately_active', phys_dir)\n",
    "very_active = import_activity_min('very_active_minutes', phys_dir)\n",
    "\n",
    "# Pickle the data for future use \n",
    "sedentary_minutes.to_pickle(\"data/sedentary_minutes.pkl\")\n",
    "lightly_active.to_pickle(\"data/lightly_active.pkl\")\n",
    "moderately_active.to_pickle(\"data/moderately_active.pkl\")\n",
    "very_active.to_pickle(\"data/very_active.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "id": "bf82c131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "dateTime         \n",
       "2017-07-18      0\n",
       "2017-07-19     37"
      ]
     },
     "execution_count": 1343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderately_active.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "id": "102fbf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value    11\n",
       "Name: 2017-07-29 00:00:00, dtype: int64"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of getting a value for a specific date \n",
    "moderately_active.loc['07/29/17']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf18443",
   "metadata": {},
   "source": [
    "### RESTING HEARTRATE\n",
    "\n",
    "Import resting heartrate from JSON. \n",
    "\n",
    "The final table `resting heartrate` will be indexed by date (in US/Pacific), with a heartrate value, and error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "id": "ebb17f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing resting_heartrate data \n",
    "resting_heartrate_nested = import_data_from_dir('resting_heart_rate', phys_dir)\n",
    "# The data in this dataframe is nested, and only the last column ('value') has the needed data \n",
    "# NOTE: json_normalize will drop rows where values come in as 'none'... not obvious in documentation\n",
    "resting_heartrate = pd.json_normalize(resting_heartrate_nested['value'])\n",
    "# Drop any rows with a NaN value \n",
    "resting_heartrate.dropna(how='any', inplace=True)\n",
    "# Make 'date' the index, and convert it to a Datetime data type \n",
    "resting_heartrate.set_index(pd.DatetimeIndex(resting_heartrate['date']), inplace=True)\n",
    "# Drop the old date column \n",
    "resting_heartrate.drop('date', axis=1, inplace=True)\n",
    "\n",
    "resting_heartrate.to_pickle(\"data/resting_heartrate.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "id": "cdbf07b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value    52.782105\n",
       "error    26.761181\n",
       "Name: 2022-07-29 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of getting a resting_heartrate value for a specific date \n",
    "resting_heartrate.loc['2022-07-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "id": "e68e23f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>52.782105</td>\n",
       "      <td>26.761181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-30</th>\n",
       "      <td>50.288383</td>\n",
       "      <td>10.639998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value      error\n",
       "date                            \n",
       "2022-07-29  52.782105  26.761181\n",
       "2022-07-30  50.288383  10.639998"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resting_heartrate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9147564",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "Now that all the data is imported, it's time to explore and clean it. \n",
    "\n",
    "Head to `clean_and_explore.ipynb`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
