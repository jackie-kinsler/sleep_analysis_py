{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5ef33e",
   "metadata": {},
   "source": [
    "interesting directories: \n",
    "Other\n",
    "Physical Activity \n",
    "Sleep \n",
    "Stress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff980c",
   "metadata": {},
   "source": [
    "Things to explore:\n",
    "1. how to save the data between uses (so I don't have to read from file every time) \n",
    "\n",
    "    pickling? \n",
    "    creating a csv? \n",
    "    creating a sql database to pull in? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740b488",
   "metadata": {},
   "source": [
    "plan: \n",
    "keep tables (bpm, sleep, activity, sleep temperature etc.) separate until I get a daily summary for each activity \n",
    "merge all the tables together using date as the primary key \n",
    "daily sleep will be the response variabel \n",
    "everything else will be explanatory variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fce65fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respiratory Rate Summary \n",
      "Stress Score.csv\n",
      "Daily SpO2 \n",
      "Computed Temperature \n",
      "sleep_score.csv\n",
      "Daily Respiratory Rate Summary \n",
      "estimated_oxygen_variation\n",
      "Active Zone Minutes \n",
      "Daily Heart Rate Variability Summary \n",
      "Device Temperature \n",
      "Heart Rate Variability Histogram \n",
      "Heart Rate Variability Details \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# this directoy only contains data relating to physical activity. Other directories \n",
    "# like account information and fitbit social activity \n",
    "path = \"/Users/jackiekinsler/projects/sleep_analysis_py/physical_data\"\n",
    " \n",
    "# to store metric types in a set\n",
    "unique_metrics = set()\n",
    "\n",
    "# dirs=directories\n",
    "for (root, dirs, file) in os.walk(path):\n",
    "    for f in file:\n",
    "        if f.endswith(\".csv\"):\n",
    "            metric = f.split(\"-\")[0]\n",
    "            unique_metrics.add(metric)\n",
    "        \n",
    "for metric in unique_metrics:\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd9409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_rate-2017-08-10.json\n",
      "heart_rate-2018-01-13.json\n",
      "heart_rate-2018-01-12.json\n",
      "heart_rate-2018-01-14.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>bpm</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-10 11:17:39</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-10 11:17:45</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-10 11:17:51</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-10 11:17:57</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-10 11:18:03</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dateTime  bpm  confidence\n",
       "0 2017-08-10 11:17:39   70           0\n",
       "1 2017-08-10 11:17:45   70           0\n",
       "2 2017-08-10 11:17:51   70           0\n",
       "3 2017-08-10 11:17:57   70           0\n",
       "4 2017-08-10 11:18:03   70           0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing BPM data \n",
    "# /Users/jackiekinsler/projects/sleep_analysis_py/test_dir\n",
    "import os\n",
    "import pandas as pd \n",
    "dfs = []\n",
    "# for file in os.listdir(\"/Users/jackiekinsler/projects/sleep_analysis_py/JacklynKinsler/Physical_Activity\"):\n",
    "for file in os.listdir(\"/Users/jackiekinsler/projects/sleep_analysis_py/test_dir\"):\n",
    "    if \"heart_rate-\" in file: \n",
    "        print(file)\n",
    "#         dfs.append(pd.read_json(f\"/Users/jackiekinsler/projects/sleep_analysis_py/JacklynKinsler/Physical_Activity/{file}\"))\n",
    "        dfs.append(pd.read_json(f\"/Users/jackiekinsler/projects/sleep_analysis_py/test_dir/{file}\"))\n",
    "# df = pd.concat(dfs)\n",
    "\n",
    "df_nested = pd.concat(dfs)\n",
    "df = pd.concat([df_nested.drop(['value'], axis=1), df_nested['value'].apply(pd.Series)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4800ad",
   "metadata": {},
   "source": [
    "From the Fitbit community: \n",
    "“Confidence scores indicate confidence in the accuracy of the captured data with “3” being the highest and “0” being the lowest; a score of 0 indicates no Heart Rate is detected by the Fitbit tracker and no Heart Rate is displayed on the tracker device”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c93bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.,  73.,  67.,  nan,  88.,  83.,  82.,  81.,  80.,  92.,  91.,\n",
       "        94.,  75.,  74.,  65.,  57.,  69.,  68.,  97.,  96.,  90.,  89.,\n",
       "        86.,  85.,  84.,  66.,  71.,  93.,  95., 124., 139., 136., 137.,\n",
       "       135., 131., 127., 130., 129., 126., 125., 121., 101., 104.,  98.,\n",
       "        87.,  78.,  77.,  72.,  56., 103.,  61.,  63.,  62., 105., 102.,\n",
       "        99., 116., 117., 115., 108., 107., 109., 106., 100.,  79.,  48.,\n",
       "        59.,  60.,  64., 110., 112., 114., 140., 144., 149., 152., 151.,\n",
       "       148., 146., 143., 142., 119., 113., 122., 111.,  58., 156., 154.,\n",
       "       150., 138., 141., 159., 158., 157., 155., 147., 123., 118.,  76.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the values where the confidence is zero, and get the unique heartrate values \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "038af56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep-2018-07-13.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': {'deep': {'count': 5, 'minutes': 96, 'thirtyDayAvgMinutes': 89},\n",
       "  'wake': {'count': 23, 'minutes': 58, 'thirtyDayAvgMinutes': 63},\n",
       "  'light': {'count': 27, 'minutes': 228, 'thirtyDayAvgMinutes': 249},\n",
       "  'rem': {'count': 5, 'minutes': 104, 'thirtyDayAvgMinutes': 82}},\n",
       " 'data': [{'dateTime': '2018-08-11T23:58:00.000',\n",
       "   'level': 'wake',\n",
       "   'seconds': 60},\n",
       "  {'dateTime': '2018-08-11T23:59:00.000', 'level': 'light', 'seconds': 210},\n",
       "  {'dateTime': '2018-08-12T00:02:30.000', 'level': 'wake', 'seconds': 240},\n",
       "  {'dateTime': '2018-08-12T00:06:30.000', 'level': 'light', 'seconds': 270},\n",
       "  {'dateTime': '2018-08-12T00:11:00.000', 'level': 'wake', 'seconds': 390},\n",
       "  {'dateTime': '2018-08-12T00:17:30.000', 'level': 'light', 'seconds': 480},\n",
       "  {'dateTime': '2018-08-12T00:25:30.000', 'level': 'deep', 'seconds': 1290},\n",
       "  {'dateTime': '2018-08-12T00:47:00.000', 'level': 'light', 'seconds': 870},\n",
       "  {'dateTime': '2018-08-12T01:01:30.000', 'level': 'rem', 'seconds': 1170},\n",
       "  {'dateTime': '2018-08-12T01:21:00.000', 'level': 'light', 'seconds': 120},\n",
       "  {'dateTime': '2018-08-12T01:23:00.000', 'level': 'deep', 'seconds': 2190},\n",
       "  {'dateTime': '2018-08-12T01:59:30.000', 'level': 'light', 'seconds': 330},\n",
       "  {'dateTime': '2018-08-12T02:05:00.000', 'level': 'rem', 'seconds': 810},\n",
       "  {'dateTime': '2018-08-12T02:18:30.000', 'level': 'light', 'seconds': 2610},\n",
       "  {'dateTime': '2018-08-12T03:02:00.000', 'level': 'rem', 'seconds': 270},\n",
       "  {'dateTime': '2018-08-12T03:06:30.000', 'level': 'light', 'seconds': 780},\n",
       "  {'dateTime': '2018-08-12T03:19:30.000', 'level': 'wake', 'seconds': 750},\n",
       "  {'dateTime': '2018-08-12T03:32:00.000', 'level': 'light', 'seconds': 1530},\n",
       "  {'dateTime': '2018-08-12T03:57:30.000', 'level': 'deep', 'seconds': 720},\n",
       "  {'dateTime': '2018-08-12T04:09:30.000', 'level': 'light', 'seconds': 1500},\n",
       "  {'dateTime': '2018-08-12T04:34:30.000', 'level': 'rem', 'seconds': 1260},\n",
       "  {'dateTime': '2018-08-12T04:55:30.000', 'level': 'wake', 'seconds': 480},\n",
       "  {'dateTime': '2018-08-12T05:03:30.000', 'level': 'light', 'seconds': 1500},\n",
       "  {'dateTime': '2018-08-12T05:28:30.000', 'level': 'deep', 'seconds': 1470},\n",
       "  {'dateTime': '2018-08-12T05:53:00.000', 'level': 'light', 'seconds': 120},\n",
       "  {'dateTime': '2018-08-12T05:55:00.000', 'level': 'rem', 'seconds': 2820},\n",
       "  {'dateTime': '2018-08-12T06:42:00.000', 'level': 'light', 'seconds': 1680},\n",
       "  {'dateTime': '2018-08-12T07:10:00.000', 'level': 'deep', 'seconds': 360},\n",
       "  {'dateTime': '2018-08-12T07:16:00.000', 'level': 'light', 'seconds': 510},\n",
       "  {'dateTime': '2018-08-12T07:24:30.000', 'level': 'wake', 'seconds': 720},\n",
       "  {'dateTime': '2018-08-12T07:36:30.000', 'level': 'light', 'seconds': 1680}],\n",
       " 'shortData': [{'dateTime': '2018-08-11T23:58:00.000',\n",
       "   'level': 'wake',\n",
       "   'seconds': 60},\n",
       "  {'dateTime': '2018-08-12T00:00:30.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T01:19:30.000', 'level': 'wake', 'seconds': 90},\n",
       "  {'dateTime': '2018-08-12T01:56:30.000', 'level': 'wake', 'seconds': 180},\n",
       "  {'dateTime': '2018-08-12T02:02:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T02:23:00.000', 'level': 'wake', 'seconds': 60},\n",
       "  {'dateTime': '2018-08-12T02:27:00.000', 'level': 'wake', 'seconds': 60},\n",
       "  {'dateTime': '2018-08-12T02:54:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T03:41:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T03:49:30.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T04:10:30.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T04:31:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T04:34:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T05:07:30.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T05:52:00.000', 'level': 'wake', 'seconds': 60},\n",
       "  {'dateTime': '2018-08-12T07:16:00.000', 'level': 'wake', 'seconds': 30},\n",
       "  {'dateTime': '2018-08-12T07:47:30.000', 'level': 'wake', 'seconds': 60},\n",
       "  {'dateTime': '2018-08-12T08:00:00.000', 'level': 'wake', 'seconds': 30}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing sleep data \n",
    "# Importing BPM data \n",
    "# /Users/jackiekinsler/projects/sleep_analysis_py/test_dir\n",
    "import os\n",
    "import pandas as pd \n",
    "dfs = []\n",
    "# for file in os.listdir(\"/Users/jackiekinsler/projects/sleep_analysis_py/JacklynKinsler/Physical_Activity\"):\n",
    "for file in os.listdir(\"/Users/jackiekinsler/projects/sleep_analysis_py/test_dir\"):\n",
    "    if \"sleep-\" in file: \n",
    "        print(file)\n",
    "#         dfs.append(pd.read_json(f\"/Users/jackiekinsler/projects/sleep_analysis_py/JacklynKinsler/Physical_Activity/{file}\"))\n",
    "        dfs.append(pd.read_json(f\"/Users/jackiekinsler/projects/sleep_analysis_py/test_dir/{file}\"))\n",
    "# df = pd.concat(dfs)\n",
    "\n",
    "df_sleep_nested = pd.concat(dfs)\n",
    "\n",
    "# df = pd.concat([df_nested.drop(['value'], axis=1), df_nested['value'].apply(pd.Series)], axis=1)\n",
    "df_sleep_nested.head()\n",
    "df_sleep_nested.loc[0,'levels']\n",
    "# the summary of the sleep data seems to have everything interesting (cumulative data)\n",
    "# the rest of the levels column is super detailed information about each type and duration of sleep segment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3316c74",
   "metadata": {},
   "source": [
    "sleep score in fitbit: \n",
    "source: https://help.fitbit.com/articles/en_US/Help_article/2439.htm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea653b19",
   "metadata": {},
   "source": [
    "Note: shortData is only included for stages sleep logs and includes wake periods that are 3 minutes or less in duration. This distinction is to simplify graphically distinguishing short wakes from longer wakes, but they are physiologically equivalent.\n",
    "\n",
    "from: https://dev.fitbit.com/build/reference/web-api/sleep/get-sleep-log-by-date-range/#:~:text=Note%3A%20shortData%20is%20only%20included,but%20they%20are%20physiologically%20equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42b1cf",
   "metadata": {},
   "source": [
    "sleep score is in a .csv with seemingly 1 row per day "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
